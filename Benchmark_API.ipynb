{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioblend import galaxy\n",
    "import requests, json, os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filepath = \"/home/md.tusar/work_1/api.py\"\n",
    "with open(filepath) as fp:\n",
    "    exec(fp.read()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = galaxy.GalaxyInstance(url = api_url, key = api_key, verify = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for workflow in gi.workflows.get_workflows():\n",
    "    if workflow['name'] == 'Transcriptomics RNA Seq Counts To Genes':\n",
    "        break\n",
    "        \n",
    "for library in gi.libraries.get_libraries():\n",
    "    if library['name'] == 'researcher01':\n",
    "        break\n",
    "\n",
    "        \n",
    "for folder in gi.libraries.get_folders(library_id = library['id']):\n",
    "    if folder['name'] == '/wFlow_data':\n",
    "        try:\n",
    "            for data in gi.folders.show_folder(folder_id = folder['id'], contents = True)['folder_contents']:\n",
    "                if data['name'] == 'Seqdata.tabular':\n",
    "                    RNA_data_1 = data['id']\n",
    "                elif data['name'] == 'Sampleinfo.tabular':\n",
    "                    RNA_data_2 = data['id']\n",
    "                else:\n",
    "                    continue\n",
    "        except:\n",
    "            print('Error in getting folder')\n",
    "            pass\n",
    "\n",
    "\n",
    "        \n",
    "i = 0\n",
    "\n",
    "while i <= 100:\n",
    "    i += 1\n",
    "    try:\n",
    "        gi.workflows.invoke_workflow(workflow_id = workflow['id'], \n",
    "                                     inputs = {'0': {'id': RNA_data_1, 'src': 'ld'},\n",
    "                                               '1': {'id': RNA_data_2, 'src': 'ld'}},\n",
    "                                     params = None, history_name = 'Transcriptomics RNA-Sequencing counts to genes ' + str(i),\n",
    "                                     import_inputs_to_history = True, replacement_params = None,\n",
    "                                     allow_tool_state_corrections = None)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8a72a9a90df70b20', 'e98ef83f52349b9a', '8ef77c0b9a2e8f61', 'c9e6d3334aa430f4', '0b37776e18390093', '46be9598e9c0ce99', 'd836242eec778a25', '227ea2970ce75d92', '6c322868fc97a6e5', '6e7233e069aad1a7', '43d619180bf1008a', '9c18ad129e678b2a', '2a4bf9d66c01414a', 'd33e32db742aed56', '1877a09319a433f5', 'b72738259af9fa3d', 'e30e45a2bfba9d97', '0005d27f1dc662c8', '1c084ec747652f8f', 'b7ea60de91649a75', '6c528a25ae52bbbf', '66219e410e539604', '14a3106b3b289bac', '1a8959d51fcc7f07', '2f5f01f38a8b48d1', 'f29b25b2abcdb977', 'a8539f6d9115ffe7', '603e7db97773b4d1', '38d70b27d179c236', '5bb18c11f5b70a41', '7f09d52a860db821', '4eb3d2698c4eef35', 'dfaae394464c0006', '56688e7db014eaac', '13c0ef3deca537cc', '3589dd416c0a42dc', 'b735ed9e5e005602', '7e1ddb768ae0c642', '873e7cabc1ca72b6', 'e516d7c43b2ce824', 'd4ba94a00b5aa576', '2992db8cf1d3093e', '13120e62d0fbb985', '78de61449bdc08e1', 'fee08c51df578e3d', '1c84aa7fc4490e6d', '8c59bbd49fe7aae1', 'd9619a5b836f6d08', 'b7c1ba819fdfdf8c', 'ac456db7f5e0a302', 'f2f5db583bb871d6', '920c23ba6ef2e3da', '51af33325a250fc7', '06667aeed86075d0', 'b1cd55a75be0e1ad', '2d3bcd1e8acf8008', 'bb7d1d57fc91145a', '99ed17d238360087', 'b4a9efd5c50010ba', 'b3a78854daef4a5a', '52ea4fd71e9f7c3f', 'aa0047f9020b2560', 'aa57f14b92934351', 'd343a822bd747ee4', '634f2991fe1a386d', '2ea0c1fdff88d4e3', 'e3975ca73c9a5b3e', '274562dbbefea26a', '8a0ce16aaf04f32a', 'f661fa6ec4dab99b', '2f4933c7d721d5e8', '5fd01fa3c70d0408', '9b305a114b324ccf', '4e3a2bbe2997e144', '8d307d4b8eda3571', '19d75dd4fb3c5cd7', '2c9ee33ffa7ccc6f', '02290d3eb960301f', '3509a83a05cae1d5', 'c8990a1b374598b0', '39e509f92cecc7d6', '9082c3dc6588cf4d', 'c4fa4dcd0ef9867a', 'a89326c04f05a73f', '6307f2c62d3ca619', '2db84b196cb92302', '44def14be693a1c2', 'a5e7909db9879e3a', 'a3ff968b01c9046c', '84f63edc852e8a15', '05198bb3e1b33188', '46d87cd113e75617', '7b326180327c3fcc', '8ad39366bdad8699', '7b162ce545dceed9', '153f67c9d7e0d19a', '6d2d4099ead26222', '7ef8021ae23ac2fc', 'dfd15528ee538abe', 'bd0beca16aa307c6', 'ba1915f3923e3bf1'] 101\n"
     ]
    }
   ],
   "source": [
    "History_trans_rna_id = []\n",
    "\n",
    "for history in gi.histories.get_histories():\n",
    "    if 'Transcriptomics RNA-Sequencing' in history['name']:\n",
    "        History_trans_rna_id.append(history['id'])\n",
    "    else:\n",
    "        continue\n",
    "print(History_trans_rna_id, len(History_trans_rna_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707\n"
     ]
    }
   ],
   "source": [
    "RNA_transcrip_job_ids = []\n",
    "\n",
    "for his in History_trans_rna_id:\n",
    "    for job in gi.jobs.get_jobs():\n",
    "        if job['history_id'] == his:\n",
    "            RNA_transcrip_job_ids.append(job['id'])\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "print(len(RNA_transcrip_job_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gia = galaxy.GalaxyInstance(url = 'https://**********/', key = '***********', verify = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606\n"
     ]
    }
   ],
   "source": [
    "RNA_job_Time = []\n",
    "\n",
    "for job in RNA_transcrip_job_ids:\n",
    "    abc = json.loads(requests.get(f\"https://**********/api/jobs/{job}?full=true\", params = gia.default_params, verify = False).content)\n",
    "    if not abc['job_metrics']:\n",
    "        continue\n",
    "    else:\n",
    "        RNA_job_Time.append(int(float(abc['job_metrics'][0]['raw_value'])))\n",
    "        \n",
    "print(len(RNA_job_Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45, 48, 8, 8, 10, 7, 47, 48, 9, 7, 8, 9, 46, 47, 8, 8, 9, 7, 48, 52, 10, 7, 10, 7, 47, 52, 8, 8, 9, 8, 64, 46, 9, 8, 9, 7, 48, 56, 9, 8, 7, 9, 67, 49, 9, 8, 8, 8, 48, 50, 11, 8, 8, 8, 56, 46, 8, 8, 8, 7, 55, 50, 10, 7, 7, 8, 57, 51, 9, 8, 10, 8, 62, 49, 8, 10, 7, 9, 62, 51, 7, 9, 7, 9, 49, 50, 8, 8, 10, 8, 66, 49, 7, 9, 9, 8, 49, 47, 9, 8, 9, 8, 68, 51, 8, 9, 7, 8, 68, 49, 8, 8, 8, 8, 48, 49, 9, 8, 8, 8, 63, 47, 10, 7, 7, 8, 65, 49, 9, 7, 9, 6, 66, 46, 10, 8, 7, 8, 62, 49, 7, 8, 7, 8, 63, 50, 8, 9, 8, 8, 66, 50, 8, 9, 7, 8, 59, 45, 8, 8, 9, 8, 63, 53, 8, 7, 9, 7, 62, 48, 8, 9, 8, 8, 64, 50, 7, 9, 7, 9, 66, 47, 7, 8, 7, 7, 68, 43, 7, 9, 8, 7, 58, 48, 7, 7, 8, 6, 65, 50, 8, 8, 8, 8, 60, 50, 9, 9, 8, 7, 65, 47, 7, 7, 7, 8, 60, 48, 8, 9, 7, 8, 63, 47, 8, 9, 8, 8, 65, 44, 8, 8, 8, 8, 64, 46, 10, 8, 9, 8, 63, 49, 8, 7, 7, 7, 66, 47, 9, 8, 10, 7, 61, 49, 8, 9, 8, 9, 67, 49, 8, 9, 7, 9, 64, 49, 7, 8, 8, 7, 66, 45, 8, 8, 8, 7, 65, 48, 8, 8, 8, 8, 70, 56, 7, 8, 10, 7, 65, 52, 8, 7, 9, 8, 63, 45, 6, 8, 8, 8, 65, 49, 8, 9, 7, 7, 70, 49, 7, 8, 7, 9, 69, 47, 9, 7, 7, 8, 63, 49, 8, 9, 9, 9, 66, 49, 8, 8, 9, 8, 61, 53, 9, 8, 8, 7, 62, 47, 10, 7, 7, 9, 65, 47, 8, 9, 9, 8, 65, 46, 8, 6, 8, 7, 64, 51, 8, 7, 7, 8, 62, 51, 10, 9, 9, 7, 68, 51, 8, 8, 6, 8, 66, 49, 10, 8, 8, 8, 62, 46, 7, 8, 7, 8, 65, 46, 9, 8, 8, 6, 66, 43, 7, 9, 7, 9, 61, 51, 8, 8, 8, 8, 66, 47, 9, 9, 7, 8, 62, 49, 7, 9, 8, 9, 65, 51, 8, 8, 7, 8, 63, 51, 8, 10, 6, 9, 65, 50, 9, 7, 8, 7, 62, 43, 8, 7, 8, 7, 62, 50, 9, 8, 8, 8, 71, 47, 7, 9, 7, 7, 63, 45, 8, 8, 7, 9, 65, 49, 8, 7, 8, 7, 67, 47, 7, 9, 8, 8, 69, 47, 8, 7, 9, 8, 62, 47, 9, 7, 8, 7, 62, 50, 10, 8, 7, 9, 64, 48, 8, 7, 8, 7, 71, 44, 8, 8, 8, 7, 68, 49, 9, 7, 8, 8, 65, 45, 8, 7, 8, 8, 62, 50, 7, 8, 8, 7, 68, 47, 8, 9, 7, 8, 63, 46, 8, 7, 6, 8, 65, 46, 8, 9, 8, 8, 63, 47, 8, 9, 8, 10, 67, 45, 8, 8, 7, 8, 61, 48, 9, 7, 9, 8, 63, 43, 7, 9, 7, 8, 61, 47, 8, 9, 6, 8, 61, 41, 8, 8, 6, 9, 63, 47, 8, 7, 8, 7, 61, 46, 7, 9, 6, 8, 61, 49, 9, 8, 7, 8, 62, 48, 8, 7, 7, 7, 62, 47, 7, 9, 7, 7, 64, 46, 8, 8, 7, 5]\n"
     ]
    }
   ],
   "source": [
    "print(RNA_job_Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "RJT = list(map(list, zip(*([iter(RNA_job_Time)]*6))))\n",
    "print(len(RJT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[126, 128, 125, 134, 132, 143, 137, 149, 133, 133, 137, 143, 145, 145, 133, 148, 130, 151, 149, 130, 142, 145, 145, 141, 146, 148, 137, 147, 143, 146, 142, 142, 134, 147, 143, 141, 140, 143, 141, 145, 141, 147, 144, 149, 143, 142, 145, 158, 149, 138, 145, 150, 147, 147, 148, 146, 142, 146, 140, 145, 148, 149, 149, 138, 142, 141, 144, 146, 144, 147, 147, 146, 135, 145, 148, 140, 144, 146, 148, 140, 146, 142, 146, 149, 141, 142, 147, 138, 144, 145, 143, 142, 137, 139, 133, 140, 137, 142, 139, 139, 138]\n"
     ]
    }
   ],
   "source": [
    "OS_RJT = []\n",
    "\n",
    "for time in RJT:\n",
    "    c = 0\n",
    "    for i in time:\n",
    "        c += i\n",
    "    OS_RJT.append(c)\n",
    "    \n",
    "print(OS_RJT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gene Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for workflow in gi.workflows.get_workflows():\n",
    "    if workflow['name'] == 'GO Enrichment Workflow':\n",
    "        break\n",
    "        \n",
    "\n",
    "for folder in gi.libraries.get_folders(library_id = library['id']):\n",
    "    if folder['name'] == '/wFlow_data':\n",
    "        try:\n",
    "            for data in gi.folders.show_folder(folder_id = folder['id'], contents = True)['folder_contents']:\n",
    "                if data['name'] == 'drosophila_gene_association.fb':\n",
    "                    GO_data_1 = data['id']\n",
    "                elif data['name'] == 'go.obo':\n",
    "                    GO_data_2 = data['id']\n",
    "                elif data['name'] == 'trapnellPopulation.tab':\n",
    "                    GO_data_3 = data['id']\n",
    "                else:\n",
    "                    continue\n",
    "            try:\n",
    "                GO_datasets = {'0': {'id': GO_data_1, 'src': 'ld'},\n",
    "                               '1': {'id': GO_data_2, 'src': 'ld'},\n",
    "                               '2': {'id': GO_data_3, 'src': 'ld'},\n",
    "                               '3': {'id': GO_data_3, 'src': 'ld'},\n",
    "                               '4': {'id': GO_data_3, 'src': 'ld'},\n",
    "                               '5': {'id': GO_data_3, 'src': 'ld'},\n",
    "                               '6': {'id': GO_data_2, 'src': 'ld'},\n",
    "                               '7': {'id': GO_data_3, 'src': 'ld'},\n",
    "                               '8': {'id': GO_data_3, 'src': 'ld'}}\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"Error in generating dataset\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Error in geting the folder\")\n",
    "            \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < 50:\n",
    "    i += 1\n",
    "    try:\n",
    "        gi.workflows.invoke_workflow(workflow_id = workflow['id'], \n",
    "                                     inputs = GO_datasets,\n",
    "                                     params = None, history_name = 'Gene Ontology Enrichment Analysis' + str(i),\n",
    "                                     import_inputs_to_history = True, replacement_params = None,\n",
    "                                     allow_tool_state_corrections = None)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"The workflow is not invoked\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "History_GO_id = []\n",
    "\n",
    "for history in gi.histories.get_histories():\n",
    "    if 'Gene Ontology Enrichment' in history['name']:\n",
    "        History_GO_id.append(history['id'])\n",
    "    else:\n",
    "        continue\n",
    "print(len(History_GO_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "GO_job_ids = []\n",
    "\n",
    "for his in History_GO_id:\n",
    "    for job in gi.jobs.get_jobs():\n",
    "        if job['history_id'] == his:\n",
    "            GO_job_ids.append(job['id'])\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "print(len(GO_job_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73, 68, 66, 75, 70, 77, 71, 112, 10, 11, 39, 67, 66, 69, 70, 107, 74, 10, 73, 12, 71, 71, 80, 111, 72, 67, 69, 72, 10, 12, 69, 84, 71, 112, 72, 74, 72, 70, 12, 14, 70, 74, 83, 75, 113, 68, 71, 73, 11, 12, 72, 72, 85, 72, 110, 71, 67, 70, 12, 11, 72, 68, 86, 104, 70, 66, 70, 73, 13, 10, 74, 75, 79, 72, 111, 70, 68, 75, 11, 14, 73, 74, 83, 72, 110, 67, 71, 71, 12, 12, 76, 72, 84, 104, 70, 66, 74, 68, 13, 12, 73, 72, 87, 71, 108, 70, 66, 69, 14, 11, 71, 83, 74, 70, 107, 73, 74, 72, 12, 12, 82, 74, 71, 68, 67, 11, 11, 114, 73, 74, 69, 74, 83, 73, 71, 103, 12, 71, 12, 70, 73, 78, 73, 70, 112, 72, 70, 69, 12, 11, 76, 85, 75, 110, 10, 73, 68, 70, 73, 14, 69, 82, 72, 107, 71, 69, 73, 70, 11, 10, 73, 70, 81, 118, 74, 71, 72, 72, 12, 11, 72, 86, 77, 105, 72, 74, 76, 76, 11, 12, 73, 87, 75, 71, 67, 69, 114, 74, 12, 11, 76, 74, 85, 107, 73, 66, 73, 71, 12, 12, 71, 69, 83, 69, 117, 68, 69, 68, 10, 10, 73, 71, 85, 112, 69, 75, 72, 71, 11, 11, 71, 73, 85, 67, 111, 72, 73, 74, 13, 12, 75, 74, 84, 69, 68, 71, 114, 74, 13, 12, 74, 80, 71, 67, 68, 71, 108, 13, 12, 81, 74, 83, 74, 73, 114, 75, 74, 13, 11, 70, 72, 75, 75, 74, 71, 111, 71, 73, 13, 13, 74, 83, 70, 69, 115, 71, 73, 71, 12, 13, 67, 83, 74, 66, 107, 11, 71, 71, 71, 12, 74, 85, 72, 109, 66, 73, 73, 69, 11, 11, 71, 74, 79, 66, 110, 72, 12, 73, 72, 12, 64, 83, 74, 66, 70, 111, 12, 73, 72, 9, 73, 68, 80, 103, 75, 71, 71, 67, 12, 11, 71, 79, 75, 70, 63, 113, 10, 74, 72, 11, 83, 68, 73, 73, 68, 74, 71, 11, 111, 11, 76, 83, 71, 69, 68, 75, 76, 11, 114, 11, 71, 84, 69, 74, 12, 66, 113, 72, 74, 11, 72, 80, 71, 67, 65, 71, 71, 113, 11, 9, 73, 86, 72, 67, 13, 68, 109, 70, 72, 12, 64, 69, 84, 73, 67, 68, 13, 110, 71, 8, 74, 76, 80, 74, 106, 66, 11, 66, 73, 9, 86, 73, 72, 71, 12, 66, 108, 71, 69, 15, 71, 82, 74, 72, 70, 63, 16, 115, 72, 12, 67, 73, 84, 103, 68, 69, 73, 74, 14, 12, 72, 71, 87, 68, 102, 71, 73, 70, 13, 12, 73, 74, 84, 112, 72, 71, 71, 68, 11, 10, 74, 90, 73, 111, 68, 68, 73, 74, 9, 14, 69, 83, 71, 72, 73, 115, 77, 76, 10, 7, 68, 82, 72, 115, 76, 75, 75, 75, 9, 7] 500\n"
     ]
    }
   ],
   "source": [
    "GO_job_Time = []\n",
    "\n",
    "for job in GO_job_ids:\n",
    "    bdc = json.loads(requests.get(f\"https://**********/api/jobs/{job}?full=true\", params = gia.default_params, verify = False).content)\n",
    "    if not bdc['job_metrics']:\n",
    "        continue\n",
    "    else:\n",
    "        GO_job_Time.append(int(float(bdc['job_metrics'][0]['raw_value'])))\n",
    "        \n",
    "print(GO_job_Time, len(GO_job_Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[73, 68, 66, 75, 70, 77, 71, 112, 10, 11], [39, 67, 66, 69, 70, 107, 74, 10, 73, 12], [71, 71, 80, 111, 72, 67, 69, 72, 10, 12], [69, 84, 71, 112, 72, 74, 72, 70, 12, 14], [70, 74, 83, 75, 113, 68, 71, 73, 11, 12], [72, 72, 85, 72, 110, 71, 67, 70, 12, 11], [72, 68, 86, 104, 70, 66, 70, 73, 13, 10], [74, 75, 79, 72, 111, 70, 68, 75, 11, 14], [73, 74, 83, 72, 110, 67, 71, 71, 12, 12], [76, 72, 84, 104, 70, 66, 74, 68, 13, 12], [73, 72, 87, 71, 108, 70, 66, 69, 14, 11], [71, 83, 74, 70, 107, 73, 74, 72, 12, 12], [82, 74, 71, 68, 67, 11, 11, 114, 73, 74], [69, 74, 83, 73, 71, 103, 12, 71, 12, 70], [73, 78, 73, 70, 112, 72, 70, 69, 12, 11], [76, 85, 75, 110, 10, 73, 68, 70, 73, 14], [69, 82, 72, 107, 71, 69, 73, 70, 11, 10], [73, 70, 81, 118, 74, 71, 72, 72, 12, 11], [72, 86, 77, 105, 72, 74, 76, 76, 11, 12], [73, 87, 75, 71, 67, 69, 114, 74, 12, 11], [76, 74, 85, 107, 73, 66, 73, 71, 12, 12], [71, 69, 83, 69, 117, 68, 69, 68, 10, 10], [73, 71, 85, 112, 69, 75, 72, 71, 11, 11], [71, 73, 85, 67, 111, 72, 73, 74, 13, 12], [75, 74, 84, 69, 68, 71, 114, 74, 13, 12], [74, 80, 71, 67, 68, 71, 108, 13, 12, 81], [74, 83, 74, 73, 114, 75, 74, 13, 11, 70], [72, 75, 75, 74, 71, 111, 71, 73, 13, 13], [74, 83, 70, 69, 115, 71, 73, 71, 12, 13], [67, 83, 74, 66, 107, 11, 71, 71, 71, 12], [74, 85, 72, 109, 66, 73, 73, 69, 11, 11], [71, 74, 79, 66, 110, 72, 12, 73, 72, 12], [64, 83, 74, 66, 70, 111, 12, 73, 72, 9], [73, 68, 80, 103, 75, 71, 71, 67, 12, 11], [71, 79, 75, 70, 63, 113, 10, 74, 72, 11], [83, 68, 73, 73, 68, 74, 71, 11, 111, 11], [76, 83, 71, 69, 68, 75, 76, 11, 114, 11], [71, 84, 69, 74, 12, 66, 113, 72, 74, 11], [72, 80, 71, 67, 65, 71, 71, 113, 11, 9], [73, 86, 72, 67, 13, 68, 109, 70, 72, 12], [64, 69, 84, 73, 67, 68, 13, 110, 71, 8], [74, 76, 80, 74, 106, 66, 11, 66, 73, 9], [86, 73, 72, 71, 12, 66, 108, 71, 69, 15], [71, 82, 74, 72, 70, 63, 16, 115, 72, 12], [67, 73, 84, 103, 68, 69, 73, 74, 14, 12], [72, 71, 87, 68, 102, 71, 73, 70, 13, 12], [73, 74, 84, 112, 72, 71, 71, 68, 11, 10], [74, 90, 73, 111, 68, 68, 73, 74, 9, 14], [69, 83, 71, 72, 73, 115, 77, 76, 10, 7], [68, 82, 72, 115, 76, 75, 75, 75, 9, 7]]\n"
     ]
    }
   ],
   "source": [
    "GOT = list(map(list, zip(*([iter(GO_job_Time)]*10))))\n",
    "print(GOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[633, 587, 635, 650, 650, 642, 632, 649, 645, 639, 641, 648, 645, 638, 640, 654, 634, 654, 661, 653, 649, 634, 650, 651, 654, 645, 661, 648, 651, 633, 643, 641, 634, 631, 638, 643, 654, 646, 630, 642, 627, 635, 643, 647, 637, 639, 646, 654, 653, 654]\n"
     ]
    }
   ],
   "source": [
    "OS_GOT = []\n",
    "\n",
    "for time in GOT:\n",
    "    c = 0\n",
    "    for i in time:\n",
    "        c += i\n",
    "    OS_GOT.append(c)\n",
    "    \n",
    "print(OS_GOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Cell QC - scater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for workflow in gi.workflows.get_workflows():\n",
    "    if workflow['name'] == 'SC - QC with scater':\n",
    "        break\n",
    "        \n",
    "for folder in gi.libraries.get_folders(library_id = library['id']):\n",
    "    if folder['name'] == '/wFlow_data':\n",
    "        try:\n",
    "            for data in gi.folders.show_folder(folder_id = folder['id'], contents = True)['folder_contents']:\n",
    "                if data['name'] == '[annotation.txt].tabular':\n",
    "                    data_1 = data['id']\n",
    "                elif data['name'] == '[counts.txt].tabular':\n",
    "                    data_2 = data['id']\n",
    "                elif data['name'] == 'https://zenodo.org/record/3386291/files/mt_controls.txt':\n",
    "                    data_3 = data['id']\n",
    "                else:\n",
    "                    continue\n",
    "        except:\n",
    "            print(\"Error in getting folder\")\n",
    "            pass\n",
    "        \n",
    "SC_inputs = {'0': {'id': data_1, 'src': 'ld'}, '1': {'id': data_2, 'src': 'ld'}, '2': {'id': data_3, 'src': 'ld'}}\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < 100:\n",
    "    i += 1\n",
    "    try:\n",
    "        gi.workflows.invoke_workflow(workflow_id = workflow['id'], inputs = SC_inputs,\n",
    "                                     params = None, history_name = 'Single Cell - QC with scater' + str(i),\n",
    "                                     import_inputs_to_history = True, replacement_params = None,\n",
    "                                     allow_tool_state_corrections = None)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"The workflow is not invoked\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "History_SCQC_id = []\n",
    "\n",
    "for history in gi.histories.get_histories():\n",
    "    if 'Single Cell - QC' in history['name']:\n",
    "        History_SCQC_id.append(history['id'])\n",
    "    else:\n",
    "        continue\n",
    "print(len(History_SCQC_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just to make a cross check if the programm works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b705194793707ae5',\n",
       " '964664dd9eb13095',\n",
       " '7d83dea28f2ec7cc',\n",
       " '72f7664cb8ff9a95',\n",
       " '83f2d7a51071d13c']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "History_SCQC_id[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 52, 39, 46, 32]\n"
     ]
    }
   ],
   "source": [
    "Single = []\n",
    "Single_time = []\n",
    "\n",
    "for job in gi.jobs.get_jobs():\n",
    "    if job['history_id'] == '83f2d7a51071d13c':\n",
    "        Single.append(job['id'])\n",
    "        \n",
    "        \n",
    "for job in Single:\n",
    "    bdc = json.loads(requests.get(f\"https://**********/api/jobs/{job}?full=true\", params = gia.default_params, verify = False).content)\n",
    "    Single_time.append(int(float(bdc['job_metrics'][0]['raw_value'])))\n",
    "    \n",
    "print(Single_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross check just only make sure it works correctly\n",
    "\n",
    "a = [31, 48, 45, 38, 42]\n",
    "b = [37, 46, 34, 43, 36]\n",
    "c = [35, 31, 41, 36, 38]\n",
    "d = [42, 42, 42, 38, 35]\n",
    "e = [42, 52, 39, 46, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 48, 45, 38, 42, 37, 46, 34, 43, 36, 35, 31, 41, 36, 38, 42, 42, 42, 38, 35, 42, 52, 39, 46, 32]\n"
     ]
    }
   ],
   "source": [
    "Single = []\n",
    "Single_time = []\n",
    "\n",
    "for his in History_SCQC_id[0:5]:\n",
    "    for job in gi.jobs.get_jobs():\n",
    "        if job['history_id'] == his:\n",
    "            Single.append(job['id'])\n",
    "            \n",
    "\n",
    "for job in Single:\n",
    "    bdc = json.loads(requests.get(f\"https://**********/api/jobs/{job}?full=true\", params = gia.default_params, verify = False).content)\n",
    "    Single_time.append(int(float(bdc['job_metrics'][0]['raw_value'])))\n",
    "    \n",
    "print(Single_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "SCQC_job_ids = []\n",
    "\n",
    "for his in History_SCQC_id:\n",
    "    for job in gi.jobs.get_jobs():\n",
    "        if job['history_id'] == his:\n",
    "            SCQC_job_ids.append(job['id'])\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "print(len(SCQC_job_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "SCQC_job_Time = []\n",
    "\n",
    "for job in SCQC_job_ids:\n",
    "    bdc = json.loads(requests.get(f\"https://**********/api/jobs/{job}?full=true\", params = gia.default_params, verify = False).content)\n",
    "    if not bdc['job_metrics']:\n",
    "        continue\n",
    "    else:\n",
    "        SCQC_job_Time.append(int(float(bdc['job_metrics'][0]['raw_value'])))\n",
    "        \n",
    "print(len(SCQC_job_Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31, 48, 45, 38, 42], [37, 46, 34, 43, 36], [35, 31, 41, 36, 38], [42, 42, 42, 38, 35], [42, 52, 39, 46, 32], [41, 53, 42, 36, 32], [51, 45, 37, 38, 32], [44, 42, 34, 48, 31], [40, 33, 49, 37, 31], [47, 48, 36, 33, 32], [36, 42, 34, 48, 30], [46, 43, 44, 39, 39], [34, 44, 36, 42, 35], [35, 47, 36, 42, 32], [41, 39, 42, 35, 40], [37, 43, 39, 47, 37], [45, 38, 50, 35, 29], [45, 35, 43, 36, 34], [52, 38, 46, 39, 36], [49, 44, 41, 40, 32], [41, 42, 48, 43, 35], [40, 42, 44, 48, 29], [44, 49, 35, 39, 31], [51, 46, 35, 41, 33], [46, 35, 48, 37, 37], [41, 44, 39, 45, 35], [41, 37, 33, 45, 36], [45, 35, 37, 45, 35], [48, 45, 46, 43, 35], [42, 44, 46, 48, 34], [39, 38, 39, 42, 33], [41, 42, 38, 45, 35], [43, 38, 43, 38, 35], [45, 42, 38, 48, 37], [44, 43, 44, 39, 32], [38, 52, 40, 34, 34], [40, 46, 40, 49, 36], [38, 55, 40, 37, 41], [40, 46, 35, 49, 32], [46, 38, 41, 51, 32], [41, 43, 47, 41, 36], [47, 36, 45, 41, 34], [44, 46, 40, 44, 39], [45, 44, 32, 36, 34], [43, 41, 40, 36, 42], [35, 45, 51, 43, 32], [41, 45, 36, 47, 38], [37, 45, 39, 43, 38], [37, 49, 42, 43, 37], [40, 51, 36, 46, 35], [36, 48, 43, 37, 34], [48, 40, 39, 35, 43], [42, 32, 36, 45, 44], [41, 55, 33, 50, 33], [37, 45, 47, 40, 39], [49, 40, 46, 40, 44], [47, 40, 35, 43, 30], [38, 45, 35, 38, 33], [36, 47, 47, 40, 31], [39, 45, 42, 46, 34], [39, 46, 44, 44, 31], [40, 45, 42, 49, 32], [46, 38, 42, 44, 31], [45, 39, 39, 45, 36], [39, 45, 47, 47, 37], [39, 45, 36, 49, 31], [41, 47, 34, 40, 41], [37, 45, 35, 36, 43], [42, 39, 41, 48, 43], [46, 41, 45, 39, 39], [35, 49, 37, 51, 37], [43, 36, 37, 44, 35], [42, 40, 42, 54, 36], [39, 41, 43, 36, 35], [46, 41, 46, 38, 31], [36, 47, 42, 43, 32], [46, 36, 49, 39, 40], [39, 47, 41, 42, 40], [45, 38, 41, 45, 45], [43, 41, 41, 42, 32], [34, 49, 43, 37, 34], [37, 44, 44, 36, 32], [45, 39, 41, 45, 31], [47, 42, 39, 43, 35], [44, 39, 40, 45, 44], [46, 42, 40, 37, 29], [45, 36, 49, 42, 36], [44, 36, 36, 40, 36], [40, 51, 41, 41, 40], [43, 39, 41, 41, 50], [36, 45, 43, 46, 42], [42, 33, 43, 39, 48], [44, 39, 41, 49, 38], [40, 53, 47, 46, 43], [40, 49, 37, 49, 36], [48, 34, 37, 43, 38], [54, 42, 42, 44, 35], [39, 45, 36, 48, 33], [42, 36, 46, 41, 32], [48, 39, 36, 48, 32]]\n"
     ]
    }
   ],
   "source": [
    "SCQCJT = list(map(list, zip(*([iter(SCQC_job_Time)]*5))))\n",
    "print(SCQCJT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[204, 196, 181, 199, 211, 204, 203, 199, 190, 196, 190, 211, 191, 192, 197, 203, 197, 193, 211, 206, 209, 203, 198, 206, 203, 204, 192, 197, 217, 214, 191, 201, 197, 210, 202, 198, 211, 211, 202, 208, 208, 203, 213, 191, 202, 206, 207, 202, 208, 208, 198, 205, 199, 212, 208, 219, 195, 189, 201, 206, 204, 208, 201, 204, 215, 200, 203, 196, 213, 210, 209, 195, 214, 194, 202, 200, 210, 209, 214, 199, 197, 193, 201, 206, 212, 194, 208, 192, 213, 214, 212, 205, 211, 229, 211, 200, 217, 201, 197, 203] 100\n"
     ]
    }
   ],
   "source": [
    "OS_SCQCJT = []\n",
    "\n",
    "for time in SCQCJT:\n",
    "    a = 0\n",
    "    for i in time:\n",
    "        a += i\n",
    "    OS_SCQCJT.append(a)\n",
    "    \n",
    "print(OS_SCQCJT, len(OS_SCQCJT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for workflow in gi.workflows.get_workflows():\n",
    "    if workflow['name'] == 'Formation Of Super Structures On Xi':\n",
    "        for library in gi.libraries.get_libraries():\n",
    "            if library['name'] == 'researcher01':\n",
    "                for folder in gi.libraries.get_folders(library_id = library['id']):\n",
    "                    if folder['name'] == '/epi_data':\n",
    "                        try:\n",
    "                            for data in gi.folders.show_folder(folder_id = folder['id'], contents = True)['folder_contents']:\n",
    "                                if data['name'] == '[wt_input_rep1].bam':\n",
    "                                    SS_data_1 = data['id']\n",
    "                                elif data['name'] == 'test1.fastq':\n",
    "                                    SS_data_2 = data['id']\n",
    "                                elif data['name'] == '[wt_H3K27me3_rep1].bam':\n",
    "                                    SS_data_3 = data['id']\n",
    "                                elif data['name'] == 'test2.fastq':\n",
    "                                    SS_data_4 = data['id']\n",
    "                                elif data['name'] == '[wt_CTCF_rep2].bam':\n",
    "                                    SS_data_5 = data['id']\n",
    "                                elif data['name'] == '[wt_H3K4me3_rep1].bam':\n",
    "                                    SS_data_6 = data['id']\n",
    "                                elif data['name'] == '[wt_H3K4me3_rep2].bam':\n",
    "                                    SS_data_7 = data['id']\n",
    "                                elif data['name'] == '[wt_H3K27me3_rep2].bam':\n",
    "                                    SS_data_8 = data['id']\n",
    "                                elif data['name'] == '[wt_input_rep2].bam':\n",
    "                                    SS_data_9 = data['id']\n",
    "                                elif data['name'] == '[wt_CTCF_rep1].bam':\n",
    "                                    SS_data_10 = data['id']\n",
    "                                else:\n",
    "                                    continue\n",
    "                            try:\n",
    "                                SS_dataset = {'0': {'id': SS_data_1, 'src': 'ld'},\n",
    "                                               '1': {'id': SS_data_2, 'src': 'ld'},\n",
    "                                               '2': {'id': SS_data_3, 'src': 'ld'},\n",
    "                                               '3': {'id': SS_data_4, 'src': 'ld'},\n",
    "                                               '4': {'id': SS_data_5, 'src': 'ld'},\n",
    "                                               '5': {'id': SS_data_6, 'src': 'ld'},\n",
    "                                               '6': {'id': SS_data_7, 'src': 'ld'},\n",
    "                                               '7': {'id': SS_data_8, 'src': 'ld'},\n",
    "                                               '8': {'id': SS_data_9, 'src': 'ld'}, \n",
    "                                               '9': {'id': SS_data_10, 'src': 'ld'}}\n",
    "                                i = 0\n",
    "                                \n",
    "                                while i < 10:\n",
    "                                    i += 1\n",
    "                                    try:\n",
    "                                        gi.workflows.invoke_workflow(workflow_id = workflow['id'], \n",
    "                                                                     inputs = SS_dataset,\n",
    "                                                                     params = None, history_name = 'Formation of the Super Structures on the i.-X ' + str(i),\n",
    "                                                                     import_inputs_to_history = True, replacement_params = None,\n",
    "                                                                     allow_tool_state_corrections = None)\n",
    "                                    except Exception as e:\n",
    "                                        print(e)\n",
    "                                        print(\"The workflow is not invoked\")\n",
    "                                    \n",
    "                            except Exception as e:\n",
    "                                print(e)\n",
    "                                print(\"Problem in getting the dataset\")\n",
    "                        except:\n",
    "                            print('Error in getting the folder')\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "History_SS_id = []\n",
    "\n",
    "for history in gi.histories.get_histories():\n",
    "    if 'Formation of the Super Structures on the i.-X' in history['name']:\n",
    "        History_SS_id.append(history['id'])\n",
    "    else:\n",
    "        continue\n",
    "print(len(History_SS_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "SS_job_ids = []\n",
    "\n",
    "for his in History_SS_id:\n",
    "    for job in gi.jobs.get_jobs():\n",
    "        if job['history_id'] == his:\n",
    "            SS_job_ids.append(job['id'])\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "print(len(SS_job_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "SS_job_Time = []\n",
    "\n",
    "for job in SS_job_ids:\n",
    "    bdc = json.loads(requests.get(f\"https://**********/api/jobs/{job}?full=true\", params = gia.default_params, verify = False).content)\n",
    "    if not bdc['job_metrics']:\n",
    "        continue\n",
    "    else:\n",
    "        SS_job_Time.append(int(float(bdc['job_metrics'][0]['raw_value'])))\n",
    "        \n",
    "print(len(SS_job_Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8210, 51, 1512, 18, 390, 8, 7, 12, 7, 6, 7, 5, 6, 7, 9, 8, 11, 7, 8, 6, 6, 6, 10, 7, 11, 1496, 274, 69, 43, 44, 182, 185, 24, 6, 154, 59, 39, 53, 328, 11, 260, 91, 103, 228, 14, 108, 132, 56, 176, 23], [8226, 48, 1377, 13, 367, 7, 9, 8, 7, 7, 7, 7, 6, 12, 5, 11, 10, 9, 6, 7, 8, 10, 8, 8, 8, 1513, 279, 41, 44, 180, 215, 125, 79, 57, 195, 211, 31, 72, 8, 180, 362, 295, 45, 61, 24, 15, 97, 107, 16, 107], [64, 18, 1493, 398, 7, 7, 6, 6, 7, 8, 7, 6, 11, 6, 6, 6, 6, 11, 10, 11, 8, 9570, 5, 6, 8, 1522, 130, 227, 61, 71, 29, 9, 174, 24, 298, 82, 49, 52, 207, 195, 176, 47, 62, 367, 289, 14, 98, 108, 15, 100], [61, 1401, 14, 368, 9, 8, 7, 7, 7, 7, 7, 5, 14, 7, 8, 11, 11, 9535, 8, 8, 6, 5, 5, 5, 5, 1606, 215, 126, 322, 81, 50, 52, 221, 201, 71, 30, 103, 104, 56, 180, 175, 9, 47, 60, 23, 15, 294, 374, 99, 14], [58, 17, 1486, 410, 6, 7, 5, 7, 6, 6, 7, 7, 12, 8, 8, 8, 7, 9713, 9, 6, 8, 8, 5, 5, 8, 1635, 218, 317, 57, 84, 211, 51, 172, 48, 58, 21, 14, 212, 132, 54, 71, 30, 9, 180, 373, 296, 100, 116, 15, 111], [65, 1411, 14, 403, 8, 6, 8, 8, 7, 8, 7, 6, 12, 9777, 6, 6, 5, 5, 5, 5, 6, 7, 8, 8, 8, 1608, 130, 323, 47, 53, 198, 213, 174, 30, 71, 62, 46, 373, 15, 296, 217, 59, 96, 115, 15, 112, 84, 183, 8, 22], [49, 13, 1432, 394, 8, 6, 7, 6, 6, 6, 7, 6, 9795, 5, 8, 7, 5, 5, 10, 8, 6, 6, 6, 9, 7, 1678, 85, 48, 29, 8, 77, 187, 235, 328, 138, 64, 217, 54, 231, 107, 300, 185, 391, 15, 49, 64, 22, 14, 117, 107], [52, 13, 1495, 399, 8, 6, 6, 7, 6, 6, 5, 6, 10763, 9, 5, 5, 5, 6, 5, 8, 9, 6, 6, 10, 9, 1617, 61, 332, 86, 236, 50, 139, 55, 29, 72, 10, 48, 194, 302, 213, 219, 379, 15, 102, 189, 15, 111, 102, 67, 26], [50, 13, 1484, 410, 8, 9, 7, 6, 6, 8, 7, 6, 10882, 10, 6, 9, 6, 8, 6, 10, 13, 12, 8, 7, 12, 1699, 335, 61, 237, 129, 230, 89, 209, 52, 52, 185, 28, 79, 194, 9, 48, 387, 311, 68, 22, 14, 101, 122, 112, 15], [53, 17, 1503, 399, 6, 7, 8, 7, 7, 6, 7, 8, 14076, 10, 6, 8, 9, 8, 7, 9, 7, 8, 8, 12, 8, 1705, 228, 135, 331, 215, 59, 84, 55, 381, 53, 210, 188, 30, 308, 182, 65, 78, 8, 46, 114, 112, 102, 25, 16, 15]]\n"
     ]
    }
   ],
   "source": [
    "SSJT = list(map(list, zip(*([iter(SS_job_Time)]*50))))\n",
    "print(SSJT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OS_SSJT = []\n",
    "\n",
    "for time in SSJT:\n",
    "    c = 0\n",
    "    for i in time:\n",
    "        c += i\n",
    "    OS_SSJT.append(c)\n",
    "    \n",
    "print(OS_SSJT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
